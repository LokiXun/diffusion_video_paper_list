# DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior

> "DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior" Arxiv, 2025 Feb 5
> [paper](http://arxiv.org/abs/2502.03502v1) [code]() [pdf](./2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior.pdf) [note](./2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note.md)
> Authors: Janghyeok Han, Gyujin Sim, Geonung Kim, Hyunseung Lee, Kyuha Choi, Youngseok Han, Sunghyun Cho

## Key-point

- Task
- Problems
- :label: Label:

## Contributions

## Introduction

## methods

![fig2](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig2.png)

è®¾è®¡äº† spatial å’Œ temporal ä¸¤ç§ä¼ æ’­æ–¹å¼ï¼Œæ ¹æ®åŽ»å™ªæ­¥æ•° tï¼Œå†³å®šå½“å‰åŽ»å™ªæ­¥æ•°ä½¿ç”¨ SAPï¼Œè¿˜æ˜¯ TAP çš„ä¼ æ’­æ–¹å¼ã€‚
ä½¿ç”¨ **SVD æ¡†æž¶ï¼Œä¸ºäº†åš VSRï¼ŒæŠŠ LR resize å†æå– VAE ç‰¹å¾**ï¼Œå’Œ random noise concat åœ¨ä¸€èµ·

> Fig. 2 illustrates the overall framework of DC-VSR, which is built upon the SVD framework [StabilityAI 2023]. To begin, DC-VSR upsamples ð¼ ð¿ð‘… using bicubic interpolation to match the target resolution, and obtains an upscaled video ð¼ up. It then embeds ð¼ up into the latent space using the VAE encoder [Rombach et al. 2022], obtaining a latent representation ð‘™, which consists of [ð‘™1, Â· Â· Â· ,ð‘™ð‘ ] stacked along the channel dimension where ð‘™ð‘– represents the latent of the ð‘–-th upsampled video frame

åœ¨è¾“å…¥ UNet ä¹‹å‰æ‰“æˆ 64 Ã— 64 Ã— 14 çš„ VAE å—

> The concatenated latents are then split into spatio-temporal tiles.
>
> We utilize spatio-temporal tiles of size 64 Ã— 64 Ã— 14 in the latent space, corresponding to 512Ã—512Ã—14 in the image space with a scaling factor of 8. 

å‚è€ƒå…ˆå‰æ–¹æ³•ï¼Œå¯¹ title ä¹‹é—´é‡å  50%ï¼Œä½¿ç”¨ gaussian blending :star: :star:

> . In line with previous approaches [Yang et al. 2024a; Zhou et al. 2024], spatially and temporally neighboring tiles overlap by 50%. Overlapped tiles are blended in the tile merging step in our pipeline using gaussian blending. 
>
> - "Motion-Guided Latent Diffu sion for Temporally Consistent Real-world Video Super-resolution. In European Conference on Computer Vision"
> - "Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution"



- Qï¼špatch ä¹‹é—´ä¸ä¸€è‡´ï¼Ÿ

> DC-VSR employs a tile-based approach to handle lengthy videos with large frames with a video diffusion prior. However, naÃ¯vely splitting a video into tiles may introduce spatial and temporal in consistencie

ä½¿ç”¨ SVD Self-attn ç±»ä¼¼æ–¹å¼è§£å†³

> . Likewise, video diffusion models such as SVD [StabilityAI 2023] leverage self-attention to achieve spatially and temporally coherent results. Specifically, the self-attention operation is defined as:
>
> For a certain spatial and temporal position in a video, the selfattention operation calculates the correlation between the query at position and keys at other positions, and aggregates values based on these correlations.



- Qï¼šæ‰“æˆ title äº†æ€Žä¹ˆç”¨ self-attn ï¼Ÿ

DC-VSR æŠŠ self-attn æ‹“å±•äº†ä¸€ä¸‹ï¼Œæžäº†ä¸ª SAPï¼ŒTAP

> However, when a video is split into tiles, each tile undergoes an independent attention process, resulting in spatial and temporal inconsistencies. 
>
> To address this, DC-VSR extends the self-attention operations using SAP and TAP, allowing attentions to be efficiently computed across tiles



### SAP

> However, due to the quadratic computational complexity of attention, naÃ¯ve extension of self-attention operations is practically infeasible.
>
>  Instead, to avoid the quadratic increase of the computational complexity, SAP leverages subsampled features that represent the entire areas of video frames and injects them into the self-attention operations for each tile.

å¯¹ self-attn KV concat

> We construct new sets of keys and values ð¾Ë† ð‘¡,ð‘š,ð‘› and ð‘‰Ë† ð‘¡,ð‘š,ð‘› by merging ð¾ð‘¡,ð‘š,ð‘› and ð¾ð‘¡,ð‘›, and ð‘‰ð‘¡,ð‘š,ð‘› and ð‘‰ð‘¡,ð‘›, respectively. 

![eq2](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq2.png)



### TAP

å¯¹ T ä¸Šå– KV memory

> TAP bidirectionally propagates information from a tile to its neighbor. Specifically, at each diffusion sampling step for TAP, the propagation is performed in either the forward or backward direction



### Detail-Suppression Self-Attention Guidance

ä¸€ç§ç±»ä¼¼ CFG çš„å¼•å¯¼æ–¹å¼

![eq3](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq3.png)



SAG, PAG å¯¹é«˜é¢‘ç»†èŠ‚å¢žåŠ æ‰°åŠ¨

![eq4](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq4.png)

> SAG. Both SAG [Hong et al. 2023] and PAG [Ahn et al. 2024] improve high-frequency details in synthesized images by introducing perturbation to the high-frequency details in the estimation of the unconditional noise.

![eq6](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq6.png)



- Qï¼šä½¿ç”¨ SAG/PAG + CFG è®¡ç®—é‡å¤ªå¤§äº†

> SAG and PAG noticeably improve image synthesis quality, especially when combined with CFG. However, integrating them with CFG incurs substantial computational costs.

è®¤ä¸º self-attn è‡ªå·±å°±èƒ½åŽ»æ‰¾åˆ°é«˜é¢‘ç»†èŠ‚

> self-attention layers in a denoising U-Net find image regions with similar high-frequency details, by computing weights based on the similarities between queries and keys. Then, they aggregate information from different image regions based on their weights.
>
> As noted by Wang et al. [2018a], this self-attention mechanism closely resembles bilateral filter [Tomasi and Manduchi 1998] and nonlocal means filter [Buades et al. 2005], both of which are renowned structure-preserving filters. I



å¯¹ self-attn map åŠ æƒä¸€ä¸‹

![eq7](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq7.png)

>  Inspired by this, we introduce an additional parameter **ð›¾ to control the weighting function of the selfattention operation**, similar to the weighting parameters in bilateral and non-local means filters

æŠŠ self-attn ç»™æ¢æˆ eq7ï¼Œä¸éœ€è¦è®­ç»ƒ :star:

![eq8](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq8.png)

eq7 é‡Œé¢çš„æƒé‡ï¼Œéšç€åŽ»å™ªæ­¥æ•°æ”¹å˜è€Œæ”¹å˜

![eq10](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/eq10.png)







## setting

- SVD

> To build DC-VSR, we fine-tune Imageto-Video Stable Video Diffusion (I2V-SVD) [StabilityAI 2023], which adopts the LDM framework [Rombach et al. 2022] with the EDM [Karras et al. 2022] diffusion mechanism

- REDS è®­ç»ƒ

> Following previous work [Chan et al. 2022b; Yang et al. 2024a], we merge 240 training videos and 30 test videos, reorganizing them into 266 training videos and 4 test videos, and refer to the latter as REDS4. We refer the reader to the supplementary material for more implementation details.

- RealESRGAN æž„é€ è®­ç»ƒæ•°æ®





## Experiment

> ablation study çœ‹é‚£ä¸ªæ¨¡å—æœ‰æ•ˆï¼Œæ€»ç»“ä¸€ä¸‹

![tb1](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/tb1.png)



ä¸€è‡´æ€§ä¹Ÿä¸è¡Œå•Šã€‚ã€‚ã€‚

![fig4-5](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig4-5.png)



ä½†çœ‹ç€å¼ è§‰å¾— UpAVideo å¥½

![fig7](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig7.png)



![fig9](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig9.png)



### ablation

ä¸æ”¾åŽŸå›¾èƒ½çœ‹å‡ºå•¥å‘¢ã€‚ã€‚ã€‚è¿™ä¸ªæ“ä½œå¤ªç§€äº†ã€‚ã€‚ã€‚

![fig3](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig3.png)

![fig6](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/fig6.png)



![tb2](docs/2025_02_Arxiv_DC-VSR--Spatially-and-Temporally-Consistent-Video-Super-Resolution-with-Video-Diffusion-Prior_Note/tb2.png)





## Limitations

## Summary :star2:

> learn what

### how to apply to our task

