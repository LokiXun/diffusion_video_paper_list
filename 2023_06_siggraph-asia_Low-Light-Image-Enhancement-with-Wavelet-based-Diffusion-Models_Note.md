# Low-Light Image Enhancement with Wavelet-based Diffusion Models

> "Low-Light Image Enhancement with Wavelet-based Diffusion Models" siggraph-asia, 2023 Jun 1, `DiffLL` :star:
> [paper](http://arxiv.org/abs/2306.00306v3) [web](https://dl.acm.org/doi/10.1145/3618373) [code](https://github.com/JianghaiSCU/Diffusion-Low-Light.) [pdf](./2023_06_siggraph-asia_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models.pdf) [note](./2023_06_siggraph-asia_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note.md)
> Authors: Hai Jiang, Ao Luo, Songchen Han, Haoqiang Fan, Shuaicheng Liu (Megvii)

## Key-point

- Task: LLE
- Problems
  - incorrect exposure, color distortion, or artifacts to degrade visual quality
- :label: Label:



> Diffusion-based Low-Light image enhancement approach, dubbed DiffLL

## Contributions

- ä½¿ç”¨ wavelet transformation ä¿ç•™é«˜é¢‘ç»†èŠ‚ç‰¹å¾ï¼Œæåˆ° diffusion ä¸Šé¢åš LLE

  > we present a **wavelet-based** conditional diffusion model (WCDM) that leverages the generative power of diffusion models to produce results with satisfactory perceptual fidelity.

- è®¾è®¡ wavelet transformation é¢‘åŸŸèåˆæ¨¡å— HFRM :star:

> we further design a high-frequency restoration module (HFRM) that utilizes the vertical and horizontal details of the image to complement the diagonal information for better fine-grained restoration. 

- è®¾è®¡è®­ç»ƒpipeline åŒæ—¶ forward & denoise

> We propose a new training strategy that enables WCDM to achieve content consistency during inference by performing both the forward diffusion and the denoising processes in the training phase

- SOTA & é€Ÿåº¦æ¯”ä¹‹å‰ DDIM æ–¹æ³•å¿«äº† 70 å€ï¼



## Introduction

![fig1](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig1.png)



### DWT

- Qï¼šä¸ºå•¥ç”¨ wavelet-transformation

> Specifically, we first convert the low-light image into the wavelet domain using ğ¾ times 2D discrete wavelet transformations (2D-DWT), which noticeably reduces the spatial dimension while avoiding information loss,

å°†ç‰¹å¾åˆ†è§£ä¸º K ä¸ªé¢‘åŸŸç‰¹å¾ï¼Œé™ä½ spatial domain  && æ—  information loss !

> Furthermore, the local details contained in the high-frequency coefficients are reconstructed through our welldesigned high-frequency restoration modules (HFRM), where the vertical and horizontal information is utilized to complement the diagonal details for better fine-grained details restoration



**æœ¬æ–‡ä½¿ç”¨ Haar å°æ³¢å˜æ¢ï¼Œå°†ç‰¹å¾åˆ†è§£ä¸ºä½é¢‘ç‰¹å¾ Aï¼Œä¸‰ä¸ªä¸åŒæ–¹å‘çš„é«˜é¢‘ç‰¹å¾ && ç‰¹å¾å°ºå¯¸å‡åŠ**

> we use 2D discrete wavelet transformation (2D-DWT) with Haar wavelets

![eq1](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq1.png)



- Qï¼šä¸ºä»€ä¹ˆç”¨ DM å»åšä½é¢‘çš„æ¢å¤ï¼Œä¸åšé«˜é¢‘ï¼Ÿ

![fig4](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig4.png)

**å°æ³¢å˜æ¢å‡ ä¸ªåˆ†é‡ç›´æ¥æ¢æ‰ï¼Œçœ‹çœ‹æ•ˆæœ**ï¼Œç±»ä¼¼ ablation å“ˆå“ˆå¤šæä¸€ä¸ªå›¾

1. **å°æ³¢å˜æ¢å¾—åˆ°çš„ä½é¢‘ç‰¹å¾ A å¯¹å›¾åƒæ•´ä½“å½±å“æœ€å¤§ï¼ï¼å½±å“ç¨‹åº¦å»å’Œ LowLight Image è®¡ç®— MSE çœ‹ï¼**
2. é«˜é¢‘ç‰¹å¾æ¯”è¾ƒç¨€ç–

æ‰€ä»¥ç”¨ DM å»ä¿®å¤æœ€ä¸»è¦çš„ä½é¢‘ç‰¹å¾ï¼Œå‰©ä¸‹çš„ç»†èŠ‚ç”¨ä¸ªå°æ¨¡å—æ

> As shown in Fig. 4, the images reconstructed by exchanging highfrequency coefficients still have approximately the same content as the original images, whereas the image **reconstructed by replacing the average coefficient changes the global information, resulting in the largest error with the original images.** Therefore, the primary focus on restoring the low-light image in the wavelet domain is to obtain the average coefficient that has natural illumination consistent with its normal-light counterpart. 
>
> For this purpose, we utilize the generative capability of diffusion models to restore the average coefficient, and the remaining three high-frequency coefficients are reconstructed through the proposed HFRM to facilitate local details restoration.





- Qï¼šå¦‚ä½•å‹æ¦¨ wavelet æé™ï¼Œé™ä½æ˜¾å­˜ & æ—¶é—´æ¶ˆè€—ï¼Ÿ:star:

å¯¹ä½é¢‘ç‰¹å¾ A è¿›ä¸€æ­¥ç”¨ Harr å°æ³¢å˜æ¢åˆ†è§£ K-1 ç»„ç‰¹å¾

![eq2](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq2.png)

Harr å°æ³¢èƒ½é™ä½ Spatial ç»´åº¦ï¼Œ**å°±æŠŠ A0 ä½é¢‘ç‰¹å¾ï¼Œè¿›ä¸€æ­¥åˆ†è§£ K æ¬¡ï¼Œè¿›ä¸€æ­¥é™ä½ç‰¹å¾å°ºå¯¸é™ä½æ¶ˆè€—ï¼ï¼ï¼ï¼**:star:

> Subsequently, we do diffusion operations on the $A^K_{low}$ to further improve the efficiency, and the high-frequency coefficients {$V^k_{low}$, $HV^k_{low}$, $D^k_{low}$ } are also reconstructed by the HFRMğ‘˜ .

è¿ç»­æ K æ¬¡ï¼Œç›´æ¥å°ºåº¦å˜æˆåŸæ¥çš„ $4^K$ å€ & è¿˜æ˜¯æ— æŸçš„ :star:

> In this way, our approach achieves significant decreases in inference time and computational resource consumption of the diffusion model due to 4 ğ¾ times reduction in the spatial dimension.

- Qï¼šä¸ºä»€ä¹ˆèƒ½è¿™ä¹ˆæï¼Ÿ
  1. å°æ³¢å˜æ¢é™ä½ç‰¹å¾ç©ºé—´å°ºå¯¸ï¼Œæ— æŸ
  2. åªåšä¸€æ¬¡çš„ä½é¢‘åˆ†é‡ï¼Œ**æ ¹æ® Fig4 MSE çš„å€¼çŒœæµ‹å«æœ‰å¤§çº¦ 96%ä¿¡æ¯ï¼Œä½é¢‘ä¿¡æ¯è¿˜æ˜¯å¤ªå¤šäº†**





## methods

- Qï¼šä¸ºä»€ä¹ˆä¸ç”¨ FFT?

**wavelet-transformation å¯ä»¥åšåˆ° spatial ç»´åº¦å‡åŠï¼ŒåŒæ—¶ä¸æŸå¤±ä¿¡æ¯** :star: ï¼›
è€Œ FFT å¦‚æœè¦å°ºå¯¸å‡åŠï¼Œå°±æœ‰æŸå¤±äº†ã€‚ã€‚

> The wavelet transformation can halve the spatial dimensions after each transformation without sacrificing information, while other transformation techniques, such as Fast Fourier Transformation (FFT) and Discrete Cosine Transform (DCT), are unable to achieve this level of reduction and may result in information loss.

![fig3](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig3.png)

- **2D ç¦»æ•£å°æ³¢å˜æ¢ï¼Œå¯ä»¥æŠŠå›¾åƒè½¬æ¢ä¸º K ç»„ä½ã€é«˜é¢‘ç‰¹å¾ï¼ˆä¸€ä¸ªä½é¢‘ Aï¼Œ3ä¸ªé«˜é¢‘åˆ†é‡ VHDï¼‰ && åŒæ—¶é™ä½ç‰¹å¾å°ºå¯¸** && æ— ä¿¡æ¯æŸå¤±å“¦

åœ¨é¢‘åŸŸåˆ†æˆä½é¢‘ã€é«˜é¢‘åˆ†åˆ«ä¿®å¤

- ä½é¢‘ï¼šWavelet-based DM å¯¹ä½é¢‘ç‰¹å¾ A è¿›è¡Œä¿®å¤ï¼ˆäº®åº¦ç®—ä½é¢‘ï¼Ÿï¼Ÿï¼‰
- é«˜é¢‘ï¼šç”¨æå‡ºçš„ HFRM æ



- Qï¼šdiffusion å¦‚ä½•åŠ é€Ÿï¼Ÿï¼Ÿ

ç”¨ Harr å°æ³¢è½¬åˆ°é¢‘åŸŸï¼Œåªå¤„ç†ä½é¢‘åˆ†é‡ï¼

> To address these problems, we propose a wavelet-based conditional diffusion model (WCDM) that converts the input low-light image ğ¼ ğ‘™ğ‘œğ‘¤ into the wavelet domain and performs the diffusion process on the average coefficient, which considerably reduces the spatial dimension for efficient restoration.

- Qï¼šdiffusion è®­ç»ƒæ—¶å€™å¦‚ä½•ä¼˜åŒ–é¢‘åŸŸåˆ†é‡ï¼Ÿ

![eq9](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq9.png)

**æ¯ä¸€æ­¥é¢„æµ‹å®Œå™ªå£°ï¼Œè½¬åˆ°ç‰¹å¾ç©ºé—´**ï¼Œåšé¢‘åŸŸåˆ†é‡çš„ MSE Loss

![ag1](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/ag1.png)





### HFRM

åˆå§‹ Depth Conv æå–ç‰¹å¾

å‚ç›´ & å¯¹è§’é«˜é¢‘ + æ°´å¹³ & å¯¹è§’é«˜é¢‘ cross-attn 

> . As shown in Fig. 5, we first use three depth-wise separable convolutions [Chollet 2017] for the sake of efficiency to extract the features of input coefficients, then two cross-attention layers [Hou et al. 2019] are employed to leverage the information in ğ‘‰ and ğ» to complement the details in ğ·.

![fig5](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig5.png)

- ä½¿ç”¨å¯å˜å½¢å·ç§¯èƒ½é™ä½ artifactï¼Ÿ

> By gradually increasing and decreasing the dilation rate ğ‘‘, the gridding effect can be avoided. :star:



DM åªè¦å¤„ç†æœ€å°å°ºåº¦çš„ä½é¢‘åˆ†é‡ Aï¼Œç„¶åç”¨ HFRM ä¿®é«˜é¢‘é€æ¸å ä¸Šå»

![eq10](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq10.png)



### Loss :star:

åŸå§‹ loss

![eq8](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq8.png)





DIffusion Loss + ä½é¢‘ç‰¹å¾ Loss

![eq9](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq9.png)

**Detail Loss + TV Loss** ä¼˜åŒ–é«˜é¢‘ç‰¹å¾ :star:

![eq11](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq11.png)

å†…å®¹ä¸€è‡´æ€§ Loss

![eq12](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq12.png)

> Moreover, we utilize a content loss Lğ‘ğ‘œğ‘›ğ‘¡ğ‘’ğ‘›ğ‘¡ that combines L1 loss and SSIM loss [Wang et al. 2004] to minimize the content difference between the restored image Ë†ğ¼ ğ‘™ğ‘œğ‘¤ and the reference image ğ¼â„ğ‘–ğ‘”â„



## setting

- å¯¹æ¯” 9 ä¸ªæ–¹æ³•
- The proposed network can be converged after being trained for $1 \times 10^5$ iterations on four NVIDIA RTX 2080Ti GPUs







## Experiment

> ablation study çœ‹é‚£ä¸ªæ¨¡å—æœ‰æ•ˆï¼Œæ€»ç»“ä¸€ä¸‹



é€Ÿåº¦æ¯”ä¹‹å‰ DDIM æ–¹æ³•å¿«äº† 70 å€ï¼

![fig2](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig2.png)





![tb1](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb1.png)



### acceleration

- Qï¼šå¦‚ä½•è¯´æ˜æ˜¾å­˜ & åŠ é€Ÿï¼Ÿ

ä¸åŒåˆ†è¾¨ç‡ï¼Œè®¡ç®— memory & time

![tb2](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb2.png)





### Low-Light Face Detection

> åŠ å®éªŒ

- Q**ï¼šå¦‚ä½•è¯´æ˜å¢å¼ºçš„æ•ˆæœæœ‰ç”¨ï¼Ÿ -ã€‹ã€‹ä¸å½±å“åç»­ä»»åŠ¡è¯†åˆ«** :star:

![fig9](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig9.png)



### Ablation

- ğ¾ = 1, leads to overall performance improvements while resulting in the inference time increase.
-  For a trade-off between performance and efficiency, we choose ğ¾ = 2 as the default setting.

![tb5](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb5.png)



#### **High-frequency Restoration Module**

- **åœ¨å°ºåº¦1 åŠ ä¸Šé¢‘åŸŸç‰¹å¾ä¿®å¤ï¼Œå°±æ¶¨äº† 2.2dB ï¼** :star:
- ä¾é é«˜é¢‘ç»†èŠ‚æå‡äº† 5dB!!!!

![tb6](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb6.png)



#### Loss

**Loss åšäº†ä¸€ç³»åˆ—æ“ä½œæ”¶æ•ˆçš„æå‡ä¸å¦‚æ¨¡å‹çš„æ”¹åŠ¨å¤§**

![tb7](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb7.png)

> The detail preserve loss **Lğ‘‘ğ‘’ğ‘¡ğ‘ğ‘–ğ‘™ is designed to reconstruct more image details**, thus its removal causes performance degradation. However, such **degradation is not significant relative to removing the content loss**



åŸå§‹ loss

![eq8](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq8.png)





#### Training Denoise

è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥ Denoise èå…¥é«˜é¢‘çš„èåˆï¼Œèƒ½æå‡è¾“å‡ºçš„ä¸€è‡´æ€§ï¼Œé™ä½éšæœºæ€§å¹²æ‰°

![fig10](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/fig10.png)



## Limitations

## Summary :star2:

> learn what

### how to apply to our task

- ä½¿ç”¨ Haar å°æ³¢å˜æ¢ï¼ˆ2D ç¦»æ•£å°æ³¢å˜æ¢ï¼‰ï¼Œå°†ç‰¹å¾**åˆ†è§£ä¸ºä½é¢‘ç‰¹å¾ Aï¼Œä¸‰ä¸ªä¸åŒæ–¹å‘çš„é«˜é¢‘ç‰¹å¾ && ç‰¹å¾å°ºå¯¸é™ä½ $4^K$ å€ && æ— ä¿¡æ¯æŸå¤±**
- åœ¨é¢‘åŸŸåˆ†æˆä½é¢‘ã€é«˜é¢‘åˆ†åˆ«ä¿®å¤
  - ä½é¢‘ï¼šWavelet-based DM å¯¹ä½é¢‘ç‰¹å¾ A è¿›è¡Œä¿®å¤ï¼ˆäº®åº¦ç®—ä½é¢‘ï¼Ÿï¼Ÿï¼‰
  - é«˜é¢‘ï¼šç”¨æå‡ºçš„ HFRM æ
- diffusion è®­ç»ƒé¢„æµ‹å®Œå™ªå£°ï¼Œ**è½¬æ¢åˆ°ç‰¹å¾ï¼Œå»åŠ å…¥å›¾åƒçš„ Lossï¼ˆtexture Loss + TV Loss + Content Lossï¼‰:star:**





- Qï¼šå¦‚ä½•å‹æ¦¨ wavelet æé™ï¼Œé™ä½æ˜¾å­˜ & æ—¶é—´æ¶ˆè€—ï¼Ÿ:star:

å¯¹ä½é¢‘ç‰¹å¾ A è¿›ä¸€æ­¥ç”¨ Harr å°æ³¢å˜æ¢åˆ†è§£ K-1 ç»„ç‰¹å¾

![eq2](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/eq2.png)

Harr å°æ³¢èƒ½é™ä½ Spatial ç»´åº¦ï¼Œ**å°±æŠŠ A0 ä½é¢‘ç‰¹å¾ï¼Œè¿›ä¸€æ­¥åˆ†è§£ K æ¬¡ï¼Œè¿›ä¸€æ­¥é™ä½ç‰¹å¾å°ºå¯¸é™ä½æ¶ˆè€—ï¼ï¼ï¼ï¼**:star:

> Subsequently, we do diffusion operations on the $A^K_{low}$ to further improve the efficiency, and the high-frequency coefficients {$V^k_{low}$, $HV^k_{low}$, $D^k_{low}$ } are also reconstructed by the HFRMğ‘˜ .

- Qï¼šä¸ºä»€ä¹ˆèƒ½è¿™ä¹ˆé«˜ï¼Ÿ
  1. å°æ³¢å˜æ¢é™ä½ç‰¹å¾ç©ºé—´å°ºå¯¸ï¼Œæ— æŸ
  2. åªåšä¸€æ¬¡çš„ä½é¢‘åˆ†é‡ï¼Œ**æ ¹æ® Fig4 MSE çš„å€¼çŒœæµ‹å«æœ‰å¤§çº¦ 96%ä¿¡æ¯ï¼Œä½é¢‘ä¿¡æ¯è¿˜æ˜¯å¤ªå¤šäº†**





- Qï¼šå¦‚ä½•è¯´æ˜æ˜¾å­˜ & åŠ é€Ÿï¼Ÿ

ä¸åŒåˆ†è¾¨ç‡ï¼Œè®¡ç®— memory & time

![tb2](docs/2023_06_TOG_Low-Light-Image-Enhancement-with-Wavelet-based-Diffusion-Models_Note/tb2.png)
