# Focal Self-attention for Local-Global Interactions in Vision Transformers

> "Focal Self-attention for Local-Global Interactions in Vision Transformers" NIPS, 2021 Jul, `Focal Transformer`
> [paper](https://arxiv.org/abs/2107.00641) [code](https://github.com/microsoft/Focal-Transformer)
> [paper local pdf](./2021_07_NeurIPS_Focal-Self-attention-for-Local-Global-Interactions-in-Vision-Transformers.pdf)



## methods

- multi-head SA

  MHSA 不同的头的 attn map 有着不同感受野，获取 local & global 信息，看论文 Figure 1(a)

## code

